{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ren/EXTERNAL_USB/KITTI360_DATASET/Test_data\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Nicolas model path, including real-world images, rendered images and their world pose parameters(intrinsic and extrinsic)\n",
    "'''\n",
    "ModelPath=\"/media/ren/EXTERNAL_USB/KITTI360_DATASET/Test_data\"\n",
    "\n",
    "print(ModelPath)\n",
    "\n",
    "#file read\n",
    "def imagepath(path):\n",
    "    images_path=os.path.join(ModelPath,path)\n",
    "# print(pc_path)\n",
    "    realfilelist = os.listdir(images_path)\n",
    "    realfilelist =sorted(realfilelist)\n",
    "    return realfilelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ORB(img):\n",
    "    \"\"\"\n",
    "     ORB detector\n",
    "    \"\"\"\n",
    "    orb = cv2.ORB_create(50000)\n",
    "    \"\"\"find keypoint, and calculate descriptor\"\"\"\n",
    "    kp, des = orb.detectAndCompute(img, None)\n",
    "\n",
    "    # plot keypoints\n",
    "    # img2 = cv2.drawKeypoints(img, kp, None, color=(0, 255, 0), flags=0)\n",
    "\n",
    " \n",
    "    # plt.figure(figsize=(10, 8), dpi=100)\n",
    "    # plt.imshow(img2[:, :, ::-1])\n",
    "    # plt.xticks([]), plt.yticks([])\n",
    "    # plt.show()\n",
    "    return kp, des\n",
    "\n",
    "\n",
    "\n",
    "def SIFT(img):\n",
    "    \"\"\"\n",
    "     SIFT detector\n",
    "    \"\"\"\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # SIFT keypoint detector\n",
    "    # sift instantiation \n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # sift detect and compute \n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    \n",
    "    # kp: information of keypoint, including position, scale, direction\n",
    "    # des: keypoint descriptor, corresponds to a feature vector of 128 gradient information\n",
    "\n",
    "    # image show\n",
    "    # cv2.drawKeypoints(img, kp, img, (0, 255, 0))\n",
    "\n",
    "    \n",
    "    # plt.figure(figsize=(10, 8), dpi=100)\n",
    "    # plt.imshow(img[:, :, ::-1])\n",
    "    # plt.xticks([]), plt.yticks([])\n",
    "    # plt.show()\n",
    "    return kp, des\n",
    "\n",
    "\n",
    "def SURF(img):\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    kp, des = surf.detectAndCompute(img, None)\n",
    "    # cv2.drawKeypoints(img, kp, img, (0, 255, 0))\n",
    "\n",
    "    \n",
    "    # plt.figure(figsize=(10, 8), dpi=100)\n",
    "    # plt.imshow(img[:, :, ::-1])\n",
    "    # plt.xticks([]), plt.yticks([])\n",
    "    # plt.show()\n",
    "    return kp, des\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Brute(img1, img2, kp1, kp2, des1, des2, flag):\n",
    "    \"\"\"\n",
    "    Brute Force matching\n",
    "    :param img1: image 1\n",
    "    :param img2: image 2\n",
    "    :param kp1: keypoints of frame 1True\n",
    "    :param kp2: keypoints of frame 2\n",
    "    :param des1: descriptor of frame 1\n",
    "    :param des2: descriptor of frame 2\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"img1\",len(kp1),len(kp2),len(des1),len(des2))\n",
    "    # if type(des1)!=NoneType and type(des2)!=NoneType:\n",
    "    if (flag == \"SIFT\" or flag == \"SURF\"):\n",
    "        # SIFT\n",
    "        bf = cv2.BFMatcher_create(cv2.NORM_L1, crossCheck=False)\n",
    "        ms = bf.knnMatch(des1, des2, k=2)\n",
    "    else:\n",
    "        # ORB\n",
    "        # bf = cv2.BFMatcher_create(cv2.NORM_L1, crossCheck=True)\n",
    "        bf = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=False)\n",
    "        ms = bf.match(des1, des2)\n",
    "        ms = sorted(ms, key=lambda x: x.distance)\n",
    "    # print('des1',des1.shape)\n",
    "    # print('des2',des2.shape)\n",
    "    \n",
    "    # ms = bf.match(des1, des2)\n",
    "    # ms = sorted(ms, key=lambda x: x.distance)\n",
    "    # img3 = cv2.drawMatches(img1, kp1, img2, kp2, ms, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    # cv2.imshow(\"Matches\", img3)\n",
    "    # cv2.waitKey(0)\n",
    "    return ms\n",
    "\n",
    "def FLANN(img1, img2, kp1, kp2, des1, des2, flag):\n",
    "    \"\"\"\n",
    "        2. FLANN matching\n",
    "        :param img1: image 1\n",
    "        :param img2: image 2\n",
    "        :param kp1: keypoints of frame 1\n",
    "        :param kp2: keypoints of frame 2\n",
    "        :param des1: descriptor of frame 1\n",
    "        :param des2: descriptor of frame 2\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    print(\"img1\",len(kp1),len(kp2),len(des1),len(des2))    \n",
    "    if (flag == \"SIFT\" or flag == \"SURF\"):\n",
    "        # SIFT\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm=FLANN_INDEX_KDTREE,\n",
    "                            trees=5)\n",
    "        search_params = dict(check=100)\n",
    "    else:\n",
    "        # ORB\n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params = dict(algorithm=FLANN_INDEX_LSH,\n",
    "                            table_number=6,\n",
    "                            key_size=12,\n",
    "                            multi_probe_level=1)\n",
    "        \n",
    "        \n",
    "        search_params = dict(check=100)\n",
    "    # define FLANN parameter\n",
    "    # print('des1',des1.shape)\n",
    "    # print('des2',des2.shape)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "optimization matching results\n",
    "RANSAC(RANdom SAmple Consensus)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def RANSAC(img1, img2, kp1, kp2, matches,MIN_MATCH_COUNT):\n",
    "    # MIN_MATCH_COUNT = 500\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    matchType = type(matches[0])\n",
    "    good = []\n",
    "    successful=[]\n",
    "    unsuccessful=[]\n",
    " \n",
    "    # print(matchType)\n",
    "    if isinstance(matches[0], cv2.DMatch):\n",
    "        # Search for matching\n",
    "        good = matches\n",
    "    else:\n",
    "        # knnMatch\n",
    "        ratio_threshold=0.7\n",
    "        for m, n in matches:\n",
    "            if m.distance < ratio_threshold* n.distance:\n",
    "                good.append(m)\n",
    "    # print('number',len(good))\n",
    "    \n",
    "    if len(good) > MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "        # M: 3x3 Homography matrix. last number is the error of the transformation between points on original images and target images.\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        # H.append(M)\n",
    "        # h, w = img1.shape\n",
    "        # pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "        # dst = cv2.perspectiveTransform(pts, M)\n",
    "        #\n",
    "        # img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "    else:\n",
    "        print\n",
    "        \"Not enough matches are found - %d/%d\" % (len(good), MIN_MATCH_COUNT)\n",
    "        matchesMask = None\n",
    "\n",
    "    draw_params = dict(matchColor=(0, 255, 0),  # draw matches in green color\n",
    "                       singlePointColor=None,\n",
    "                       matchesMask=matchesMask,  # draw only inliers\n",
    "                       flags=2)\n",
    "    good_match_len=len(good)\n",
    "    # print(matchesMask)\n",
    "    Suc_matching=matchesMask.count(1)\n",
    "    # print(Suc_matching)\n",
    "    # bad_match_len=outliermask.count(1)\n",
    "    # successful.append(Suc_matching)\n",
    "    Unsuc=matchesMask.count(0)\n",
    "    # print(Unsuc)\n",
    "    # unsuccessful.append(Unsuc)\n",
    "    img3 = cv2.drawMatches(img1, kp1, img2, kp2, good, None, **draw_params)\n",
    "\n",
    "    draw_params1 = dict(matchColor=(0, 255, 0),  # draw matches in green color\n",
    "                        singlePointColor=None,\n",
    "                        matchesMask=None,  # draw only inliers\n",
    "                        flags=2)\n",
    "    # print('matched',kp1.size,kp2.size)\n",
    "    img33 = cv2.drawMatches(img1, kp1, img2, kp2, good, None, **draw_params1)\n",
    "    # print(\"good len\",len(good))\n",
    "    # print(\"kp1\",kp1[0].distance)\n",
    "\n",
    "    # cv2.imshow(\"before\", img33)\n",
    "    # cv2.imshow(\"now\", img3)\n",
    "    # cv2.imwrite('matching testdata00_0000.jpg',img3)\n",
    "    # cv2.waitKey(20)\n",
    "    return good_match_len,Suc_matching,Unsuc,M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.44823034e+03 0.00000000e+00 2.11650000e+03]\n",
      " [0.00000000e+00 3.43126050e+03 1.40800000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]] [[ 9.90164574e-01  1.39503036e-01  1.06310234e-02 -2.27301571e+01]\n",
      " [-2.89960020e-02  2.78955743e-01 -9.59866098e-01  4.58700839e+00]\n",
      " [-1.36869819e-01  9.50117149e-01  2.80257125e-01  1.17073411e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# read extrinsic and intrinsic\n",
    "\n",
    "parameters=o3d.io.read_pinhole_camera_parameters(os.path.join(ModelPath,\"world_poses\",\"world_pose_00008.json\"))\n",
    "intrinsic=parameters.intrinsic.intrinsic_matrix\n",
    "extrinsic=parameters.extrinsic\n",
    "\n",
    "print(intrinsic,extrinsic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-4f8ce22778c2>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-4f8ce22778c2>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    param_frame1=o3d.io.read_pinhole_camera_parameters(os.path.join(ModelPath,\"world_poses\",\"world_pose_00%d.json\"framename1))\u001b[0m\n\u001b[0m                                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Ground Truth Value, make sure that frames are from the same sequence\n",
    "'''\n",
    "\n",
    "def GroundTruthPose(framename1,framename2):\n",
    "    param_frame1=o3d.io.read_pinhole_camera_parameters(os.path.join(ModelPath,\"world_poses\",\"world_pose_00%d.json\"framename1))\n",
    "    intri_1=param_frame1.intrinsic.intrinsic_matrix\n",
    "    extri_1=param_frame1.extrinsic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
